{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8ahCkHvQrOr"
   },
   "source": [
    "<h1><center></center></h1>\n",
    "<div style=\"display: flex; justify-content: center; margin: 0 auto;\" align=\"center\">\n",
    "  <img src=\"https://myth-ai.com/wp-content/uploads/2023/05/646f153be1e56.png\" href=\"https://myth-ai.com/\" width=\"100px\" align=\"center\">\n",
    "  <h1>Technical Assignment</h1>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <h2>\n",
    "  Sketch Generation via Diffusion Models using Sequential Strokes\n",
    "  </h2>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://github.com/googlecreativelab/quickdraw-dataset/blob/master/preview.jpg?raw=true\">\n",
    "  <figcaption>\n",
    "    Collection of 50 million drawings across 345 categories, contributed by players of the game Quick, Draw!. Drawings were captured as timestamped vectors.\n",
    "    <i>Source: <a href=\"https://quickdraw.withgoogle.com/data/\">Quick, Draw! Dataset</a>.</i>\n",
    "  </figcaption>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this project, you are expected to implement a **conditional generative diffusion model** that learns to generate hand-drawn sketches in a **stroke-by-stroke** sequential manner. Rather than generating the entire sketch at once, your model should mimic the **sequential nature of human drawing**, producing strokes one after another in a realistic and interpretable way.\n",
    "\n",
    "You will use the [Quick, Draw!](https://quickdraw.withgoogle.com/data/) dataset released by Google, which provides timestamped vector representations of user-drawn sketches across 345 object categories.\n",
    "\n",
    "---\n",
    "\n",
    "## Brief Explanation\n",
    "\n",
    "You will design and train a **separate conditional diffusion model** for each of the following three categories:\n",
    "\n",
    "- `cat`\n",
    "- `bus`\n",
    "- `rabbit`\n",
    "\n",
    "Each model must learn to generate sketches from that category using **sequential stroke data**. That means you will build **three separate models** in total‚Äîone per category.\n",
    "\n",
    "Your implementation must be documented in a reproducible Jupyter notebook, including training steps, visualizations, and both qualitative and quantitative evaluations.\n",
    "\n",
    "- Include comprehensive documentation of your approach and design decisions.\n",
    "- Provide clear training procedures, model architecture explanations, and inference code.\n",
    "- Ensure full reproducibility (running all cells should yield consistent results with fixed random seeds).\n",
    "\n",
    "---\n",
    "\n",
    "## Data Specification\n",
    "\n",
    "The Quick, Draw! dataset includes over 50 million sketches in vector format, with each sketch consisting of multiple strokes, where each stroke is a sequence of coordinates (`x`, `y`) along with timing information.\n",
    "\n",
    "You can download the raw `.ndjson` files from the this [section](#cell-id1). The following commands will download the required categories (`cat`, `bus`, `rabbit`) into the ./data directory.\n",
    "\n",
    "**‚ö†Ô∏è Note:** If you're not using Google Colab or Kaggle, make sure you have `gsutil` installed. You can install it via pip:\n",
    "\n",
    "```bash\n",
    "pip install gsutil\n",
    "```\n",
    "\n",
    "**‚ö†Ô∏è Important:** The dataset files are in [NDJSON](https://github.com/ndjson/ndjson-spec) format. Make sure to install the ndjson Python module before attempting to parse the files.\n",
    "\n",
    "```bash\n",
    "pip install ndjson\n",
    "```\n",
    "\n",
    "### Train/Test Subsets for Target Categories\n",
    "\n",
    "After downloading the dataset in the `./data` directory, extract the provided `subset.zip` file. This archive includes the predefined train/test splits for each of the three categories.\n",
    "\n",
    "```\n",
    "subset/\n",
    "‚îú‚îÄ‚îÄ cat/\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ indices.json\n",
    "‚îú‚îÄ‚îÄ bus/\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ indices.json\n",
    "‚îî‚îÄ‚îÄ rabbit/\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ indices.json\n",
    "```\n",
    "\n",
    "Each `indices` file contains a JSON structure with two keys:\n",
    "\n",
    "- `\"train\"`: list of indices for training\n",
    "- `\"test\"`: list of indices for testing\n",
    "\n",
    "**‚ö†Ô∏è Important:** Strictly adhere to these predefined splits for consistent evaluation.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "You must evaluate your model both **qualitatively** and **quantitatively**.\n",
    "\n",
    "### Quantitative Evaluation\n",
    "\n",
    "Use the following metrics to compare the real test set sketches with those generated by your model:\n",
    "\n",
    "- **FID (Fr√©chet Inception Distance)**\n",
    "- **KID (Kernel Inception Distance)**\n",
    "\n",
    "These metrics should be computed **separately for each category** using the sketches indexed under the `\"test\"` key in each category‚Äôs `indices.json` file.\n",
    "\n",
    "> **Final submission must include three FID and three KID scores‚Äîone pair per category.**\n",
    "\n",
    "### Qualitative Evaluation\n",
    "\n",
    "Provide visual demonstrations including:\n",
    "\n",
    "- Sample generated sketches for each category.\n",
    "- Your submission must include three animated GIFs (one per category) showing the stroke-by-stroke generation process, similar to `example.gif` file in the link.\n",
    "- Comparison between real and generated sketches.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "Your submission should include the following:\n",
    "\n",
    "- A well-structured **Jupyter Notebook** that:\n",
    "  - Explains your approach and design decisions\n",
    "  - Implements the conditional diffusion model\n",
    "  - Includes training procedure and inference pipeline code\n",
    "  - Presents both qualitative and quantitative results\n",
    "  - Visual examples of generated sketches for each of the 3 categories\n",
    "  - Animated GIFs demonstrating progressive sketch generation (similar to the provided example.gif)\n",
    "  - Clearly computed FID/KID scores for each category\n",
    "- Model performance analysis across categories\n",
    "- Comparison of generated vs. real sketch characteristics\n",
    "- Discussion of limitations and potential improvements\n",
    "\n",
    "\n",
    "> üîí All visualizations must be based on sketches generated by your own model. Using samples from external sources will be considered **plagiarism** and will result in disqualification.\n",
    "\n",
    "> üîÅ The notebook must be **fully reproducible**: running all cells from top to bottom should produce the same results (assuming fixed random seed).\n",
    "\n",
    "---\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "- [The Quick, Draw! Dataset](https://github.com/googlecreativelab/quickdraw-dataset)\n",
    "- [Quick, Draw! Kaggle Competition](https://www.kaggle.com/c/quickdraw-doodle-recognition/overview)\n",
    "- [Diffusion Models Overview (Lil‚ÄôLog)](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)\n",
    "- [Ha, D., & Eck, D. (2017). A neural representation of sketch drawings. arXiv preprint arXiv:1704.03477.](https://arxiv.org/pdf/1704.03477)\n",
    "- Special thanks to M. Sung, KAIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lfaHsLNkuYB"
   },
   "source": [
    "# Download the Quick, Draw! Dataset\n",
    "\n",
    "<a name=\"cell-id1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Kt2OjtIbWOAQ"
   },
   "source": [
    "# If you're not using Colab or Kaggle, uncomment the following line:\n",
    "!pip install gsutil"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ue4Lavg4XzrP"
   },
   "source": [
    "%pip install ndjson"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRD7IDkp3ltZ",
    "outputId": "b4c53999-19e1-4f54-dd60-93f2c6d6fd81"
   },
   "source": [
    "%mkdir data\n",
    "!gsutil -m cp 'gs://quickdraw_dataset/full/simplified/cat.ndjson' ./data\n",
    "!gsutil -m cp 'gs://quickdraw_dataset/full/simplified/bus.ndjson' ./data\n",
    "!gsutil -m cp 'gs://quickdraw_dataset/full/simplified/rabbit.ndjson' ./data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M00-fIER2U1-"
   },
   "source": [
    "# Solution\n",
    "\n",
    "- Briefly explain why you chose the method you did.\n",
    "- Discuss the drawbacks and advantages of your chosen method.\n",
    "- Evaluate and discuss the results for each metric."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Section 1: Data Loading and Preprocessing\n",
    "\n",
    "## Imports and Setup"
   ]
  },
  {
   "metadata": {
    "id": "WHhj6nFP2Wwi"
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load raw sketches\n",
    "with open(\"./data/cat.ndjson\", 'r') as f:\n",
    "    cat_sketches = [json.loads(line) for line in f]\n",
    "\n",
    "# Load train/test indices\n",
    "with open(\"./subset/cat/indices.json\", 'r') as f:\n",
    "    cat_indices = json.load(f)\n",
    "\n",
    "cat_train = [cat_sketches[i] for i in cat_indices[\"train\"]]\n",
    "cat_test = [cat_sketches[i] for i in cat_indices[\"test\"]]\n",
    "\n",
    "len(cat_train), len(cat_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Take first training sketch\n",
    "sketch = cat_train[0]\n",
    "drawing = sketch[\"drawing\"]\n",
    "\n",
    "# Collect all points for normalization\n",
    "all_points = []\n",
    "for stroke in drawing:\n",
    "    points = list(zip(stroke[0], stroke[1]))\n",
    "    all_points.extend(points)\n",
    "\n",
    "# Normalize to [-1, 1]\n",
    "all_x, all_y = zip(*all_points)\n",
    "min_x, max_x = min(all_x), max(all_x)\n",
    "min_y, max_y = min(all_y), max(all_y)\n",
    "width = max_x - min_x if max_x > min_x else 1\n",
    "height = max_y - min_y if max_y > min_y else 1\n",
    "\n",
    "# Build sequence: [command, x, y]\n",
    "# 0: draw, 1: pen_up, 2: pen_down, 3: end\n",
    "sequence = []\n",
    "\n",
    "for stroke in drawing:\n",
    "    sequence.append([2, 0, 0])  # pen_down\n",
    "\n",
    "    for x, y in zip(stroke[0], stroke[1]):\n",
    "        norm_x = 2 * (x - min_x) / width - 1\n",
    "        norm_y = 2 * (y - min_y) / height - 1\n",
    "        sequence.append([0, norm_x, norm_y])  # draw\n",
    "\n",
    "    sequence.append([1, 0, 0])  # pen_up\n",
    "\n",
    "sequence.append([3, 0, 0])  # end\n",
    "sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "sequence.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "current_stroke = []\n",
    "pen_down = False\n",
    "\n",
    "for command, x, y in sequence:\n",
    "    if command == 2:  # pen_down\n",
    "        pen_down = True\n",
    "        current_stroke = []\n",
    "    elif command == 1:  # pen_up\n",
    "        if pen_down and len(current_stroke) > 1:\n",
    "            xs, ys = zip(*current_stroke)\n",
    "            ax.plot(xs, ys, 'b-', linewidth=2)\n",
    "        pen_down = False\n",
    "    elif command == 0 and pen_down:  # draw\n",
    "        current_stroke.append([x, y])\n",
    "    elif command == 3:  # end\n",
    "        break\n",
    "\n",
    "ax.set_xlim(-1.2, 1.2)\n",
    "ax.set_ylim(-1.2, 1.2)\n",
    "ax.set_aspect('equal')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title(\"Preprocessed Cat Sketch\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cat_sequences = []\n",
    "max_length = 200\n",
    "\n",
    "for sketch in cat_train:\n",
    "    drawing = sketch[\"drawing\"]\n",
    "\n",
    "    # Collect and normalize points\n",
    "    all_points = []\n",
    "    for stroke in drawing:\n",
    "        all_points.extend(zip(stroke[0], stroke[1]))\n",
    "\n",
    "    if not all_points:\n",
    "        continue\n",
    "\n",
    "    all_x, all_y = zip(*all_points)\n",
    "    min_x, max_x = min(all_x), max(all_x)\n",
    "    min_y, max_y = min(all_y), max(all_y)\n",
    "    width = max_x - min_x if max_x > min_x else 1\n",
    "    height = max_y - min_y if max_y > min_y else 1\n",
    "\n",
    "    # Build sequence\n",
    "    sequence = []\n",
    "    for stroke in drawing:\n",
    "        sequence.append([2, 0, 0])\n",
    "        for x, y in zip(stroke[0], stroke[1]):\n",
    "            norm_x = 2 * (x - min_x) / width - 1\n",
    "            norm_y = 2 * (y - min_y) / height - 1\n",
    "            sequence.append([0, norm_x, norm_y])\n",
    "        sequence.append([1, 0, 0])\n",
    "    sequence.append([3, 0, 0])\n",
    "\n",
    "    # Pad or truncate\n",
    "    sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "    if len(sequence) > max_length:\n",
    "        sequence = sequence[:max_length]\n",
    "    else:\n",
    "        padding = torch.tensor([[3, 0, 0]] * (max_length - len(sequence)))\n",
    "        sequence = torch.cat([sequence, padding])\n",
    "\n",
    "    cat_sequences.append(sequence)\n",
    "\n",
    "len(cat_sequences)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]\n",
    "\n",
    "cat_dataset = SimpleDataset(cat_sequences)\n",
    "cat_loader = DataLoader(cat_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Test batch\n",
    "batch = next(iter(cat_loader))\n",
    "batch.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Section 2: Data Analysis and Visualization"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check sequence lengths distribution\n",
    "seq_lengths = [len(seq[seq[:, 0] != 3]) for seq in cat_sequences]  # Exclude padding\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(seq_lengths, bins=50, alpha=0.7)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Sequence Lengths')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(seq_lengths)\n",
    "plt.ylabel('Sequence Length')\n",
    "plt.title('Sequence Length Statistics')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "f\"Min: {min(seq_lengths)}, Max: {max(seq_lengths)}, Mean: {np.mean(seq_lengths):.1f}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count strokes per sketch (pen_down commands)\n",
    "stroke_counts = []\n",
    "for seq in cat_sequences:\n",
    "    pen_downs = (seq[:, 0] == 2).sum().item()\n",
    "    stroke_counts.append(pen_downs)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(stroke_counts, bins=range(1, max(stroke_counts)+2), alpha=0.7)\n",
    "plt.xlabel('Number of Strokes')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Stroke Counts in Cat Sketches')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "f\"Strokes per sketch - Min: {min(stroke_counts)}, Max: {max(stroke_counts)}, Mean: {np.mean(stroke_counts):.1f}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Show 6 random cat sketches\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    seq = cat_sequences[i]\n",
    "\n",
    "    current_stroke = []\n",
    "    pen_down = False\n",
    "\n",
    "    for command, x, y in seq:\n",
    "        if command == 2:  # pen_down\n",
    "            pen_down = True\n",
    "            current_stroke = []\n",
    "        elif command == 1:  # pen_up\n",
    "            if pen_down and len(current_stroke) > 1:\n",
    "                xs, ys = zip(*current_stroke)\n",
    "                ax.plot(xs, ys, 'b-', linewidth=2)\n",
    "            pen_down = False\n",
    "        elif command == 0 and pen_down:  # draw\n",
    "            current_stroke.append([x, y])\n",
    "        elif command == 3:  # end\n",
    "            break\n",
    "\n",
    "    ax.set_xlim(-1.2, 1.2)\n",
    "    ax.set_ylim(-1.2, 1.2)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(f'Cat {i+1}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract all drawing coordinates (command=0)\n",
    "all_coords = []\n",
    "for seq in cat_sequences:\n",
    "    drawing_points = seq[seq[:, 0] == 0]  # Only drawing commands\n",
    "    if len(drawing_points) > 0:\n",
    "        all_coords.append(drawing_points[:, 1:])  # x, y coordinates\n",
    "\n",
    "all_coords = torch.cat(all_coords)\n",
    "x_coords = all_coords[:, 0].numpy()\n",
    "y_coords = all_coords[:, 1].numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(x_coords, bins=50, alpha=0.7, color='red')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Count')\n",
    "plt.title('X Coordinate Distribution')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(y_coords, bins=50, alpha=0.7, color='green')\n",
    "plt.xlabel('Y Coordinate')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Y Coordinate Distribution')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(x_coords[::100], y_coords[::100], alpha=0.1, s=1)\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.title('Coordinate Scatter Plot')\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load bus and rabbit data\n",
    "categories = ['bus', 'rabbit']\n",
    "all_data = {'cat': cat_sequences}\n",
    "\n",
    "for category in categories:\n",
    "    # Load sketches\n",
    "    with open(f\"./data/{category}.ndjson\", 'r') as f:\n",
    "        sketches = [json.loads(line) for line in f]\n",
    "\n",
    "    with open(f\"./subset/{category}/indices.json\", 'r') as f:\n",
    "        indices = json.load(f)\n",
    "\n",
    "    train_sketches = [sketches[i] for i in indices[\"train\"]]\n",
    "\n",
    "    # Process sequences\n",
    "    sequences = []\n",
    "    for sketch in train_sketches:\n",
    "        drawing = sketch[\"drawing\"]\n",
    "\n",
    "        all_points = []\n",
    "        for stroke in drawing:\n",
    "            all_points.extend(zip(stroke[0], stroke[1]))\n",
    "\n",
    "        if not all_points:\n",
    "            continue\n",
    "\n",
    "        all_x, all_y = zip(*all_points)\n",
    "        min_x, max_x = min(all_x), max(all_x)\n",
    "        min_y, max_y = min(all_y), max(all_y)\n",
    "        width = max_x - min_x if max_x > min_x else 1\n",
    "        height = max_y - min_y if max_y > min_y else 1\n",
    "\n",
    "        sequence = []\n",
    "        for stroke in drawing:\n",
    "            sequence.append([2, 0, 0])\n",
    "            for x, y in zip(stroke[0], stroke[1]):\n",
    "                norm_x = 2 * (x - min_x) / width - 1\n",
    "                norm_y = 2 * (y - min_y) / height - 1\n",
    "                sequence.append([0, norm_x, norm_y])\n",
    "            sequence.append([1, 0, 0])\n",
    "        sequence.append([3, 0, 0])\n",
    "\n",
    "        sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "        if len(sequence) > 200:\n",
    "            sequence = sequence[:200]\n",
    "        else:\n",
    "            padding = torch.tensor([[3, 0, 0]] * (200 - len(sequence)))\n",
    "            sequence = torch.cat([sequence, padding])\n",
    "\n",
    "        sequences.append(sequence)\n",
    "\n",
    "    all_data[category] = sequences\n",
    "\n",
    "{k: len(v) for k, v in all_data.items()}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compare stroke counts across categories\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for i, (category, sequences) in enumerate(all_data.items()):\n",
    "    stroke_counts = []\n",
    "    for seq in sequences:\n",
    "        pen_downs = (seq[:, 0] == 2).sum().item()\n",
    "        stroke_counts.append(pen_downs)\n",
    "\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.hist(stroke_counts, bins=range(1, 20), alpha=0.7)\n",
    "    plt.xlabel('Number of Strokes')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f'{category.capitalize()} - Stroke Distribution')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, (category, sequences) in enumerate(all_data.items()):\n",
    "    seq = sequences[0]\n",
    "    ax = axes[i]\n",
    "\n",
    "    current_stroke = []\n",
    "    pen_down = False\n",
    "\n",
    "    for command, x, y in seq:\n",
    "        if command == 2:  # pen_down\n",
    "            pen_down = True\n",
    "            current_stroke = []\n",
    "        elif command == 1:  # pen_up\n",
    "            if pen_down and len(current_stroke) > 1:\n",
    "                xs, ys = zip(*current_stroke)\n",
    "                ax.plot(xs, ys, 'b-', linewidth=2)\n",
    "            pen_down = False\n",
    "        elif command == 0 and pen_down:  # draw\n",
    "            current_stroke.append([x, y])\n",
    "        elif command == 3:  # end\n",
    "            break\n",
    "\n",
    "    ax.set_xlim(-1.2, 1.2)\n",
    "    ax.set_ylim(-1.2, 1.2)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(f'{category.capitalize()} Sample')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create summary table\n",
    "summary = {}\n",
    "for category, sequences in all_data.items():\n",
    "    seq_lengths = [len(seq[seq[:, 0] != 3]) for seq in sequences]\n",
    "    stroke_counts = [(seq[:, 0] == 2).sum().item() for seq in sequences]\n",
    "\n",
    "    summary[category] = {\n",
    "        'count': len(sequences),\n",
    "        'avg_length': np.mean(seq_lengths),\n",
    "        'avg_strokes': np.mean(stroke_counts),\n",
    "        'max_length': max(seq_lengths),\n",
    "        'max_strokes': max(stroke_counts)\n",
    "    }\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(summary).T.round(2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Section 3: Model Architecture Design"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=200):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = t[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.linear1 = nn.Linear(d_model, d_model * 4)\n",
    "        self.linear2 = nn.Linear(d_model * 4, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Self attention\n",
    "        x2 = self.norm1(x)\n",
    "        x2, _ = self.self_attn(x2, x2, x2, attn_mask=mask)\n",
    "        x = x + self.dropout(x2)\n",
    "\n",
    "        # Feed forward\n",
    "        x2 = self.norm2(x)\n",
    "        x2 = self.linear2(F.relu(self.linear1(x2)))\n",
    "        x = x + self.dropout(x2)\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SketchDiffusionModel(nn.Module):\n",
    "    def __init__(self, d_model=256, nhead=8, num_layers=6, seq_len=200):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Input projection: [command, x, y] -> d_model\n",
    "        self.input_proj = nn.Linear(3, d_model)\n",
    "\n",
    "        # Time embedding\n",
    "        self.time_embed = TimeEmbedding(d_model)\n",
    "        self.time_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.pos_encoding = PositionalEncoding(d_model, seq_len)\n",
    "\n",
    "        # Transformer layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, nhead) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Output projection\n",
    "        self.output_proj = nn.Linear(d_model, 3)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # x: [batch, seq_len, 3]\n",
    "        # t: [batch]\n",
    "\n",
    "        batch_size, seq_len = x.shape[0], x.shape[1]\n",
    "\n",
    "        # Input projection\n",
    "        x = self.input_proj(x)  # [batch, seq_len, d_model]\n",
    "\n",
    "        # Add time embedding\n",
    "        t_emb = self.time_embed(t)  # [batch, d_model]\n",
    "        t_emb = self.time_proj(t_emb)  # [batch, d_model]\n",
    "        t_emb = t_emb.unsqueeze(1).expand(-1, seq_len, -1)  # [batch, seq_len, d_model]\n",
    "        x = x + t_emb\n",
    "\n",
    "        # Add positional encoding\n",
    "        x = self.pos_encoding(x)\n",
    "\n",
    "        # Transformer layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Output projection\n",
    "        x = self.output_proj(x)  # [batch, seq_len, 3]\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create model instance\n",
    "model = SketchDiffusionModel(d_model=256, nhead=8, num_layers=6)\n",
    "\n",
    "# Test forward pass\n",
    "batch_size = 4\n",
    "seq_len = 200\n",
    "x = torch.randn(batch_size, seq_len, 3)\n",
    "t = torch.randint(0, 1000, (batch_size,))\n",
    "\n",
    "output = model(x, t)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class NoiseSchedule:\n",
    "    def __init__(self, num_timesteps=1000, beta_start=0.0001, beta_end=0.02):\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        # Linear schedule\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "\n",
    "        # Calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n",
    "\n",
    "        # Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        self.posterior_variance = self.betas * (1. - self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)\n",
    "\n",
    "noise_schedule = NoiseSchedule()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def forward_diffusion(x0, t, noise_schedule):\n",
    "    \"\"\"Add noise to data according to diffusion schedule\"\"\"\n",
    "    device = x0.device\n",
    "\n",
    "    # Get noise schedule values\n",
    "    sqrt_alphas_cumprod_t = noise_schedule.sqrt_alphas_cumprod[t].to(device)\n",
    "    sqrt_one_minus_alphas_cumprod_t = noise_schedule.sqrt_one_minus_alphas_cumprod[t].to(device)\n",
    "\n",
    "    # Reshape for broadcasting\n",
    "    sqrt_alphas_cumprod_t = sqrt_alphas_cumprod_t.reshape(-1, 1, 1)\n",
    "    sqrt_one_minus_alphas_cumprod_t = sqrt_one_minus_alphas_cumprod_t.reshape(-1, 1, 1)\n",
    "\n",
    "    # Sample noise\n",
    "    noise = torch.randn_like(x0)\n",
    "\n",
    "    # Add noise\n",
    "    x_t = sqrt_alphas_cumprod_t * x0 + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "\n",
    "    return x_t, noise"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test forward diffusion with cat data\n",
    "sample_batch = torch.stack(cat_sequences[:8])  # Get 8 samples\n",
    "timesteps = torch.randint(0, 1000, (8,))\n",
    "\n",
    "# Add noise\n",
    "noisy_batch, noise = forward_diffusion(sample_batch, timesteps, noise_schedule)\n",
    "\n",
    "print(f\"Original batch shape: {sample_batch.shape}\")\n",
    "print(f\"Noisy batch shape: {noisy_batch.shape}\")\n",
    "print(f\"Noise shape: {noise.shape}\")\n",
    "print(f\"Timesteps: {timesteps}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def diffusion_loss(model, x0, noise_schedule, device):\n",
    "    \"\"\"Calculate diffusion loss\"\"\"\n",
    "    batch_size = x0.shape[0]\n",
    "\n",
    "    # Sample timesteps\n",
    "    t = torch.randint(0, noise_schedule.num_timesteps, (batch_size,), device=device)\n",
    "\n",
    "    # Add noise\n",
    "    x_t, noise = forward_diffusion(x0, t, noise_schedule)\n",
    "\n",
    "    # Predict noise\n",
    "    predicted_noise = model(x_t, t)\n",
    "\n",
    "    # Calculate loss (MSE between actual and predicted noise)\n",
    "    loss = F.mse_loss(predicted_noise, noise)\n",
    "\n",
    "    return loss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Move data to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "sample_batch = sample_batch.to(device)\n",
    "\n",
    "# Calculate loss\n",
    "loss = diffusion_loss(model, sample_batch, noise_schedule, device)\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Section 4: Training Pipeline"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Training hyperparameters\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 50\n",
    "batch_size = 16\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_epoch(model, dataloader, optimizer, noise_schedule, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = diffusion_loss(model, batch, noise_schedule, device)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create cat dataloader\n",
    "cat_tensor = torch.stack(cat_sequences)\n",
    "cat_dataset = SimpleDataset(cat_tensor)\n",
    "cat_loader = DataLoader(cat_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Cat dataset size: {len(cat_dataset)}\")\n",
    "print(f\"Number of batches: {len(cat_loader)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create and setup model for cats\n",
    "cat_model = SketchDiffusionModel(d_model=256, nhead=8, num_layers=6).to(device)\n",
    "cat_optimizer = optim.Adam(cat_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Move noise schedule to device\n",
    "noise_schedule.betas = noise_schedule.betas.to(device)\n",
    "noise_schedule.alphas = noise_schedule.alphas.to(device)\n",
    "noise_schedule.alphas_cumprod = noise_schedule.alphas_cumprod.to(device)\n",
    "noise_schedule.alphas_cumprod_prev = noise_schedule.alphas_cumprod_prev.to(device)\n",
    "noise_schedule.sqrt_alphas_cumprod = noise_schedule.sqrt_alphas_cumprod.to(device)\n",
    "noise_schedule.sqrt_one_minus_alphas_cumprod = noise_schedule.sqrt_one_minus_alphas_cumprod.to(device)\n",
    "noise_schedule.posterior_variance = noise_schedule.posterior_variance.to(device)\n",
    "\n",
    "print(f\"Cat model parameters: {sum(p.numel() for p in cat_model.parameters()):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop for cats\n",
    "cat_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = train_epoch(cat_model, cat_loader, cat_optimizer, noise_schedule, device)\n",
    "    cat_losses.append(avg_loss)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Plot training curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(cat_losses)\n",
    "plt.title('Cat Model Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create models directory\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "# Save cat model\n",
    "torch.save({\n",
    "    'model_state_dict': cat_model.state_dict(),\n",
    "    'optimizer_state_dict': cat_optimizer.state_dict(),\n",
    "    'loss_history': cat_losses,\n",
    "    'epoch': num_epochs\n",
    "}, './models/cat_model.pth')\n",
    "\n",
    "print(\"Cat model saved successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare bus data\n",
    "bus_tensor = torch.stack(all_data['bus'])\n",
    "bus_dataset = SimpleDataset(bus_tensor)\n",
    "bus_loader = DataLoader(bus_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize bus model\n",
    "bus_model = SketchDiffusionModel(d_model=256, nhead=8, num_layers=6).to(device)\n",
    "bus_optimizer = optim.Adam(bus_model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"Bus dataset size: {len(bus_dataset)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training loop for bus\n",
    "bus_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = train_epoch(bus_model, bus_loader, bus_optimizer, noise_schedule, device)\n",
    "    bus_losses.append(avg_loss)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Plot training curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(bus_losses)\n",
    "plt.title('Bus Model Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save bus model\n",
    "torch.save({\n",
    "    'model_state_dict': bus_model.state_dict(),\n",
    "    'optimizer_state_dict': bus_optimizer.state_dict(),\n",
    "    'loss_history': bus_losses,\n",
    "    'epoch': num_epochs\n",
    "}, './models/bus_model.pth')\n",
    "\n",
    "print(\"Bus model saved successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare rabbit data\n",
    "rabbit_tensor = torch.stack(all_data['rabbit'])\n",
    "rabbit_dataset = SimpleDataset(rabbit_tensor)\n",
    "rabbit_loader = DataLoader(rabbit_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize rabbit model\n",
    "rabbit_model = SketchDiffusionModel(d_model=256, nhead=8, num_layers=6).to(device)\n",
    "rabbit_optimizer = optim.Adam(rabbit_model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"Rabbit dataset size: {len(rabbit_dataset)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training loop for rabbit\n",
    "rabbit_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = train_epoch(rabbit_model, rabbit_loader, rabbit_optimizer, noise_schedule, device)\n",
    "    rabbit_losses.append(avg_loss)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Plot training curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rabbit_losses)\n",
    "plt.title('Rabbit Model Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save rabbit model\n",
    "torch.save({\n",
    "    'model_state_dict': rabbit_model.state_dict(),\n",
    "    'optimizer_state_dict': rabbit_optimizer.state_dict(),\n",
    "    'loss_history': rabbit_losses,\n",
    "    'epoch': num_epochs\n",
    "}, './models/rabbit_model.pth')\n",
    "\n",
    "print(\"Rabbit model saved successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot all training curves together\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(cat_losses, label='Cat', color='orange')\n",
    "plt.plot(bus_losses, label='Bus', color='blue')\n",
    "plt.plot(rabbit_losses, label='Rabbit', color='green')\n",
    "plt.title('Training Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(cat_losses[-20:], label='Cat', color='orange')\n",
    "plt.plot(bus_losses[-20:], label='Bus', color='blue')\n",
    "plt.plot(rabbit_losses[-20:], label='Rabbit', color='green')\n",
    "plt.title('Last 20 Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print final training statistics\n",
    "final_losses = {\n",
    "    'cat': cat_losses[-1],\n",
    "    'bus': bus_losses[-1],\n",
    "    'rabbit': rabbit_losses[-1]\n",
    "}\n",
    "\n",
    "print(\"Final Training Losses:\")\n",
    "for category, loss in final_losses.items():\n",
    "    print(f\"  {category.capitalize()}: {loss:.4f}\")\n",
    "\n",
    "print(f\"\\nTotal training time: {num_epochs} epochs per model\")\n",
    "print(\"All models saved to ./models/ directory\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VEme3no2Xpc"
   },
   "source": [
    "# References\n",
    "\n",
    "‚ùó Do not forget to include the references you used when filling out the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERleXF7C2Zl9"
   },
   "source": [
    "- []()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
