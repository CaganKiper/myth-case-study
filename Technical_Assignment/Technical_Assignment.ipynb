{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8ahCkHvQrOr"
   },
   "source": [
    "<h1><center></center></h1>\n",
    "<div style=\"display: flex; justify-content: center; margin: 0 auto;\" align=\"center\">\n",
    "  <img src=\"https://myth-ai.com/wp-content/uploads/2023/05/646f153be1e56.png\" href=\"https://myth-ai.com/\" width=\"100px\" align=\"center\">\n",
    "  <h1>Technical Assignment</h1>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <h2>\n",
    "  Sketch Generation via Diffusion Models using Sequential Strokes\n",
    "  </h2>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://github.com/googlecreativelab/quickdraw-dataset/blob/master/preview.jpg?raw=true\">\n",
    "  <figcaption>\n",
    "    Collection of 50 million drawings across 345 categories, contributed by players of the game Quick, Draw!. Drawings were captured as timestamped vectors.\n",
    "    <i>Source: <a href=\"https://quickdraw.withgoogle.com/data/\">Quick, Draw! Dataset</a>.</i>\n",
    "  </figcaption>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this project, you are expected to implement a **conditional generative diffusion model** that learns to generate hand-drawn sketches in a **stroke-by-stroke** sequential manner. Rather than generating the entire sketch at once, your model should mimic the **sequential nature of human drawing**, producing strokes one after another in a realistic and interpretable way.\n",
    "\n",
    "You will use the [Quick, Draw!](https://quickdraw.withgoogle.com/data/) dataset released by Google, which provides timestamped vector representations of user-drawn sketches across 345 object categories.\n",
    "\n",
    "---\n",
    "\n",
    "## Brief Explanation\n",
    "\n",
    "You will design and train a **separate conditional diffusion model** for each of the following three categories:\n",
    "\n",
    "- `cat`\n",
    "- `bus`\n",
    "- `rabbit`\n",
    "\n",
    "Each model must learn to generate sketches from that category using **sequential stroke data**. That means you will build **three separate models** in total‚Äîone per category.\n",
    "\n",
    "Your implementation must be documented in a reproducible Jupyter notebook, including training steps, visualizations, and both qualitative and quantitative evaluations.\n",
    "\n",
    "- Include comprehensive documentation of your approach and design decisions.\n",
    "- Provide clear training procedures, model architecture explanations, and inference code.\n",
    "- Ensure full reproducibility (running all cells should yield consistent results with fixed random seeds).\n",
    "\n",
    "---\n",
    "\n",
    "## Data Specification\n",
    "\n",
    "The Quick, Draw! dataset includes over 50 million sketches in vector format, with each sketch consisting of multiple strokes, where each stroke is a sequence of coordinates (`x`, `y`) along with timing information.\n",
    "\n",
    "You can download the raw `.ndjson` files from the this [section](#cell-id1). The following commands will download the required categories (`cat`, `bus`, `rabbit`) into the ./data directory.\n",
    "\n",
    "**‚ö†Ô∏è Note:** If you're not using Google Colab or Kaggle, make sure you have `gsutil` installed. You can install it via pip:\n",
    "\n",
    "```bash\n",
    "pip install gsutil\n",
    "```\n",
    "\n",
    "**‚ö†Ô∏è Important:** The dataset files are in [NDJSON](https://github.com/ndjson/ndjson-spec) format. Make sure to install the ndjson Python module before attempting to parse the files.\n",
    "\n",
    "```bash\n",
    "pip install ndjson\n",
    "```\n",
    "\n",
    "### Train/Test Subsets for Target Categories\n",
    "\n",
    "After downloading the dataset in the `./data` directory, extract the provided `subset.zip` file. This archive includes the predefined train/test splits for each of the three categories.\n",
    "\n",
    "```\n",
    "subset/\n",
    "‚îú‚îÄ‚îÄ cat/\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ indices.json\n",
    "‚îú‚îÄ‚îÄ bus/\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ indices.json\n",
    "‚îî‚îÄ‚îÄ rabbit/\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ indices.json\n",
    "```\n",
    "\n",
    "Each `indices` file contains a JSON structure with two keys:\n",
    "\n",
    "- `\"train\"`: list of indices for training\n",
    "- `\"test\"`: list of indices for testing\n",
    "\n",
    "**‚ö†Ô∏è Important:** Strictly adhere to these predefined splits for consistent evaluation.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "You must evaluate your model both **qualitatively** and **quantitatively**.\n",
    "\n",
    "### Quantitative Evaluation\n",
    "\n",
    "Use the following metrics to compare the real test set sketches with those generated by your model:\n",
    "\n",
    "- **FID (Fr√©chet Inception Distance)**\n",
    "- **KID (Kernel Inception Distance)**\n",
    "\n",
    "These metrics should be computed **separately for each category** using the sketches indexed under the `\"test\"` key in each category‚Äôs `indices.json` file.\n",
    "\n",
    "> **Final submission must include three FID and three KID scores‚Äîone pair per category.**\n",
    "\n",
    "### Qualitative Evaluation\n",
    "\n",
    "Provide visual demonstrations including:\n",
    "\n",
    "- Sample generated sketches for each category.\n",
    "- Your submission must include three animated GIFs (one per category) showing the stroke-by-stroke generation process, similar to `example.gif` file in the link.\n",
    "- Comparison between real and generated sketches.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "Your submission should include the following:\n",
    "\n",
    "- A well-structured **Jupyter Notebook** that:\n",
    "  - Explains your approach and design decisions\n",
    "  - Implements the conditional diffusion model\n",
    "  - Includes training procedure and inference pipeline code\n",
    "  - Presents both qualitative and quantitative results\n",
    "  - Visual examples of generated sketches for each of the 3 categories\n",
    "  - Animated GIFs demonstrating progressive sketch generation (similar to the provided example.gif)\n",
    "  - Clearly computed FID/KID scores for each category\n",
    "- Model performance analysis across categories\n",
    "- Comparison of generated vs. real sketch characteristics\n",
    "- Discussion of limitations and potential improvements\n",
    "\n",
    "\n",
    "> üîí All visualizations must be based on sketches generated by your own model. Using samples from external sources will be considered **plagiarism** and will result in disqualification.\n",
    "\n",
    "> üîÅ The notebook must be **fully reproducible**: running all cells from top to bottom should produce the same results (assuming fixed random seed).\n",
    "\n",
    "---\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "- [The Quick, Draw! Dataset](https://github.com/googlecreativelab/quickdraw-dataset)\n",
    "- [Quick, Draw! Kaggle Competition](https://www.kaggle.com/c/quickdraw-doodle-recognition/overview)\n",
    "- [Diffusion Models Overview (Lil‚ÄôLog)](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)\n",
    "- [Ha, D., & Eck, D. (2017). A neural representation of sketch drawings. arXiv preprint arXiv:1704.03477.](https://arxiv.org/pdf/1704.03477)\n",
    "- Special thanks to M. Sung, KAIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lfaHsLNkuYB"
   },
   "source": [
    "# Download the Quick, Draw! Dataset\n",
    "\n",
    "<a name=\"cell-id1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Kt2OjtIbWOAQ"
   },
   "source": [
    "# If you're not using Colab or Kaggle, uncomment the following line:\n",
    "!pip install gsutil"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ue4Lavg4XzrP"
   },
   "source": [
    "%pip install ndjson"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRD7IDkp3ltZ",
    "outputId": "b4c53999-19e1-4f54-dd60-93f2c6d6fd81"
   },
   "source": [
    "%mkdir data\n",
    "!gsutil -m cp 'gs://quickdraw_dataset/full/simplified/cat.ndjson' ./data\n",
    "!gsutil -m cp 'gs://quickdraw_dataset/full/simplified/bus.ndjson' ./data\n",
    "!gsutil -m cp 'gs://quickdraw_dataset/full/simplified/rabbit.ndjson' ./data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M00-fIER2U1-"
   },
   "source": [
    "# Solution\n",
    "\n",
    "- Briefly explain why you chose the method you did.\n",
    "- Discuss the drawbacks and advantages of your chosen method.\n",
    "- Evaluate and discuss the results for each metric."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Section 1: Data Loading and Preprocessing\n",
    "\n",
    "## Imports and Setup"
   ]
  },
  {
   "metadata": {
    "id": "WHhj6nFP2Wwi"
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load raw sketches\n",
    "with open(\"./data/cat.ndjson\", 'r') as f:\n",
    "    cat_sketches = [json.loads(line) for line in f]\n",
    "\n",
    "# Load train/test indices\n",
    "with open(\"./subset/cat/indices.json\", 'r') as f:\n",
    "    cat_indices = json.load(f)\n",
    "\n",
    "cat_train = [cat_sketches[i] for i in cat_indices[\"train\"]]\n",
    "cat_test = [cat_sketches[i] for i in cat_indices[\"test\"]]\n",
    "\n",
    "len(cat_train), len(cat_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Take first training sketch\n",
    "sketch = cat_train[0]\n",
    "drawing = sketch[\"drawing\"]\n",
    "\n",
    "# Collect all points for normalization\n",
    "all_points = []\n",
    "for stroke in drawing:\n",
    "    points = list(zip(stroke[0], stroke[1]))\n",
    "    all_points.extend(points)\n",
    "\n",
    "# Normalize to [-1, 1]\n",
    "all_x, all_y = zip(*all_points)\n",
    "min_x, max_x = min(all_x), max(all_x)\n",
    "min_y, max_y = min(all_y), max(all_y)\n",
    "width = max_x - min_x if max_x > min_x else 1\n",
    "height = max_y - min_y if max_y > min_y else 1\n",
    "\n",
    "# Build sequence: [command, x, y]\n",
    "# 0: draw, 1: pen_up, 2: pen_down, 3: end\n",
    "sequence = []\n",
    "\n",
    "for stroke in drawing:\n",
    "    sequence.append([2, 0, 0])  # pen_down\n",
    "\n",
    "    for x, y in zip(stroke[0], stroke[1]):\n",
    "        norm_x = 2 * (x - min_x) / width - 1\n",
    "        norm_y = 2 * (y - min_y) / height - 1\n",
    "        sequence.append([0, norm_x, norm_y])  # draw\n",
    "\n",
    "    sequence.append([1, 0, 0])  # pen_up\n",
    "\n",
    "sequence.append([3, 0, 0])  # end\n",
    "sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "sequence.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "current_stroke = []\n",
    "pen_down = False\n",
    "\n",
    "for command, x, y in sequence:\n",
    "    if command == 2:  # pen_down\n",
    "        pen_down = True\n",
    "        current_stroke = []\n",
    "    elif command == 1:  # pen_up\n",
    "        if pen_down and len(current_stroke) > 1:\n",
    "            xs, ys = zip(*current_stroke)\n",
    "            ax.plot(xs, ys, 'b-', linewidth=2)\n",
    "        pen_down = False\n",
    "    elif command == 0 and pen_down:  # draw\n",
    "        current_stroke.append([x, y])\n",
    "    elif command == 3:  # end\n",
    "        break\n",
    "\n",
    "ax.set_xlim(-1.2, 1.2)\n",
    "ax.set_ylim(-1.2, 1.2)\n",
    "ax.set_aspect('equal')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title(\"Preprocessed Cat Sketch\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cat_sequences = []\n",
    "max_length = 200\n",
    "\n",
    "for sketch in cat_train:\n",
    "    drawing = sketch[\"drawing\"]\n",
    "\n",
    "    # Collect and normalize points\n",
    "    all_points = []\n",
    "    for stroke in drawing:\n",
    "        all_points.extend(zip(stroke[0], stroke[1]))\n",
    "\n",
    "    if not all_points:\n",
    "        continue\n",
    "\n",
    "    all_x, all_y = zip(*all_points)\n",
    "    min_x, max_x = min(all_x), max(all_x)\n",
    "    min_y, max_y = min(all_y), max(all_y)\n",
    "    width = max_x - min_x if max_x > min_x else 1\n",
    "    height = max_y - min_y if max_y > min_y else 1\n",
    "\n",
    "    # Build sequence\n",
    "    sequence = []\n",
    "    for stroke in drawing:\n",
    "        sequence.append([2, 0, 0])\n",
    "        for x, y in zip(stroke[0], stroke[1]):\n",
    "            norm_x = 2 * (x - min_x) / width - 1\n",
    "            norm_y = 2 * (y - min_y) / height - 1\n",
    "            sequence.append([0, norm_x, norm_y])\n",
    "        sequence.append([1, 0, 0])\n",
    "    sequence.append([3, 0, 0])\n",
    "\n",
    "    # Pad or truncate\n",
    "    sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "    if len(sequence) > max_length:\n",
    "        sequence = sequence[:max_length]\n",
    "    else:\n",
    "        padding = torch.tensor([[3, 0, 0]] * (max_length - len(sequence)))\n",
    "        sequence = torch.cat([sequence, padding])\n",
    "\n",
    "    cat_sequences.append(sequence)\n",
    "\n",
    "len(cat_sequences)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]\n",
    "\n",
    "cat_dataset = SimpleDataset(cat_sequences)\n",
    "cat_loader = DataLoader(cat_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Test batch\n",
    "batch = next(iter(cat_loader))\n",
    "batch.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Section 2: Data Analysis and Visualization"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check sequence lengths distribution\n",
    "seq_lengths = [len(seq[seq[:, 0] != 3]) for seq in cat_sequences]  # Exclude padding\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(seq_lengths, bins=50, alpha=0.7)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Sequence Lengths')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(seq_lengths)\n",
    "plt.ylabel('Sequence Length')\n",
    "plt.title('Sequence Length Statistics')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "f\"Min: {min(seq_lengths)}, Max: {max(seq_lengths)}, Mean: {np.mean(seq_lengths):.1f}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count strokes per sketch (pen_down commands)\n",
    "stroke_counts = []\n",
    "for seq in cat_sequences:\n",
    "    pen_downs = (seq[:, 0] == 2).sum().item()\n",
    "    stroke_counts.append(pen_downs)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(stroke_counts, bins=range(1, max(stroke_counts)+2), alpha=0.7)\n",
    "plt.xlabel('Number of Strokes')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Stroke Counts in Cat Sketches')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "f\"Strokes per sketch - Min: {min(stroke_counts)}, Max: {max(stroke_counts)}, Mean: {np.mean(stroke_counts):.1f}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Show 6 random cat sketches\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    seq = cat_sequences[i]\n",
    "\n",
    "    current_stroke = []\n",
    "    pen_down = False\n",
    "\n",
    "    for command, x, y in seq:\n",
    "        if command == 2:  # pen_down\n",
    "            pen_down = True\n",
    "            current_stroke = []\n",
    "        elif command == 1:  # pen_up\n",
    "            if pen_down and len(current_stroke) > 1:\n",
    "                xs, ys = zip(*current_stroke)\n",
    "                ax.plot(xs, ys, 'b-', linewidth=2)\n",
    "            pen_down = False\n",
    "        elif command == 0 and pen_down:  # draw\n",
    "            current_stroke.append([x, y])\n",
    "        elif command == 3:  # end\n",
    "            break\n",
    "\n",
    "    ax.set_xlim(-1.2, 1.2)\n",
    "    ax.set_ylim(-1.2, 1.2)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(f'Cat {i+1}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract all drawing coordinates (command=0)\n",
    "all_coords = []\n",
    "for seq in cat_sequences:\n",
    "    drawing_points = seq[seq[:, 0] == 0]  # Only drawing commands\n",
    "    if len(drawing_points) > 0:\n",
    "        all_coords.append(drawing_points[:, 1:])  # x, y coordinates\n",
    "\n",
    "all_coords = torch.cat(all_coords)\n",
    "x_coords = all_coords[:, 0].numpy()\n",
    "y_coords = all_coords[:, 1].numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(x_coords, bins=50, alpha=0.7, color='red')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Count')\n",
    "plt.title('X Coordinate Distribution')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(y_coords, bins=50, alpha=0.7, color='green')\n",
    "plt.xlabel('Y Coordinate')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Y Coordinate Distribution')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(x_coords[::100], y_coords[::100], alpha=0.1, s=1)\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.title('Coordinate Scatter Plot')\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load bus and rabbit data\n",
    "categories = ['bus', 'rabbit']\n",
    "all_data = {'cat': cat_sequences}\n",
    "\n",
    "for category in categories:\n",
    "    # Load sketches\n",
    "    with open(f\"./data/{category}.ndjson\", 'r') as f:\n",
    "        sketches = [json.loads(line) for line in f]\n",
    "\n",
    "    with open(f\"./subset/{category}/indices.json\", 'r') as f:\n",
    "        indices = json.load(f)\n",
    "\n",
    "    train_sketches = [sketches[i] for i in indices[\"train\"]]\n",
    "\n",
    "    # Process sequences\n",
    "    sequences = []\n",
    "    for sketch in train_sketches:\n",
    "        drawing = sketch[\"drawing\"]\n",
    "\n",
    "        all_points = []\n",
    "        for stroke in drawing:\n",
    "            all_points.extend(zip(stroke[0], stroke[1]))\n",
    "\n",
    "        if not all_points:\n",
    "            continue\n",
    "\n",
    "        all_x, all_y = zip(*all_points)\n",
    "        min_x, max_x = min(all_x), max(all_x)\n",
    "        min_y, max_y = min(all_y), max(all_y)\n",
    "        width = max_x - min_x if max_x > min_x else 1\n",
    "        height = max_y - min_y if max_y > min_y else 1\n",
    "\n",
    "        sequence = []\n",
    "        for stroke in drawing:\n",
    "            sequence.append([2, 0, 0])\n",
    "            for x, y in zip(stroke[0], stroke[1]):\n",
    "                norm_x = 2 * (x - min_x) / width - 1\n",
    "                norm_y = 2 * (y - min_y) / height - 1\n",
    "                sequence.append([0, norm_x, norm_y])\n",
    "            sequence.append([1, 0, 0])\n",
    "        sequence.append([3, 0, 0])\n",
    "\n",
    "        sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "        if len(sequence) > 200:\n",
    "            sequence = sequence[:200]\n",
    "        else:\n",
    "            padding = torch.tensor([[3, 0, 0]] * (200 - len(sequence)))\n",
    "            sequence = torch.cat([sequence, padding])\n",
    "\n",
    "        sequences.append(sequence)\n",
    "\n",
    "    all_data[category] = sequences\n",
    "\n",
    "{k: len(v) for k, v in all_data.items()}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compare stroke counts across categories\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for i, (category, sequences) in enumerate(all_data.items()):\n",
    "    stroke_counts = []\n",
    "    for seq in sequences:\n",
    "        pen_downs = (seq[:, 0] == 2).sum().item()\n",
    "        stroke_counts.append(pen_downs)\n",
    "\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.hist(stroke_counts, bins=range(1, 20), alpha=0.7)\n",
    "    plt.xlabel('Number of Strokes')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f'{category.capitalize()} - Stroke Distribution')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, (category, sequences) in enumerate(all_data.items()):\n",
    "    seq = sequences[0]\n",
    "    ax = axes[i]\n",
    "\n",
    "    current_stroke = []\n",
    "    pen_down = False\n",
    "\n",
    "    for command, x, y in seq:\n",
    "        if command == 2:  # pen_down\n",
    "            pen_down = True\n",
    "            current_stroke = []\n",
    "        elif command == 1:  # pen_up\n",
    "            if pen_down and len(current_stroke) > 1:\n",
    "                xs, ys = zip(*current_stroke)\n",
    "                ax.plot(xs, ys, 'b-', linewidth=2)\n",
    "            pen_down = False\n",
    "        elif command == 0 and pen_down:  # draw\n",
    "            current_stroke.append([x, y])\n",
    "        elif command == 3:  # end\n",
    "            break\n",
    "\n",
    "    ax.set_xlim(-1.2, 1.2)\n",
    "    ax.set_ylim(-1.2, 1.2)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(f'{category.capitalize()} Sample')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create summary table\n",
    "summary = {}\n",
    "for category, sequences in all_data.items():\n",
    "    seq_lengths = [len(seq[seq[:, 0] != 3]) for seq in sequences]\n",
    "    stroke_counts = [(seq[:, 0] == 2).sum().item() for seq in sequences]\n",
    "\n",
    "    summary[category] = {\n",
    "        'count': len(sequences),\n",
    "        'avg_length': np.mean(seq_lengths),\n",
    "        'avg_strokes': np.mean(stroke_counts),\n",
    "        'max_length': max(seq_lengths),\n",
    "        'max_strokes': max(stroke_counts)\n",
    "    }\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(summary).T.round(2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Section 3: Model Architecture Design"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=200):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = t[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.linear1 = nn.Linear(d_model, d_model * 4)\n",
    "        self.linear2 = nn.Linear(d_model * 4, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Self attention\n",
    "        x2 = self.norm1(x)\n",
    "        x2, _ = self.self_attn(x2, x2, x2, attn_mask=mask)\n",
    "        x = x + self.dropout(x2)\n",
    "\n",
    "        # Feed forward\n",
    "        x2 = self.norm2(x)\n",
    "        x2 = self.linear2(F.relu(self.linear1(x2)))\n",
    "        x = x + self.dropout(x2)\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SketchDiffusionModel(nn.Module):\n",
    "    def __init__(self, d_model=256, nhead=8, num_layers=6, seq_len=200):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Input projection: [command, x, y] -> d_model\n",
    "        self.input_proj = nn.Linear(3, d_model)\n",
    "\n",
    "        # Time embedding\n",
    "        self.time_embed = TimeEmbedding(d_model)\n",
    "        self.time_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.pos_encoding = PositionalEncoding(d_model, seq_len)\n",
    "\n",
    "        # Transformer layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, nhead) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Output projection\n",
    "        self.output_proj = nn.Linear(d_model, 3)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # x: [batch, seq_len, 3]\n",
    "        # t: [batch]\n",
    "\n",
    "        batch_size, seq_len = x.shape[0], x.shape[1]\n",
    "\n",
    "        # Input projection\n",
    "        x = self.input_proj(x)  # [batch, seq_len, d_model]\n",
    "\n",
    "        # Add time embedding\n",
    "        t_emb = self.time_embed(t)  # [batch, d_model]\n",
    "        t_emb = self.time_proj(t_emb)  # [batch, d_model]\n",
    "        t_emb = t_emb.unsqueeze(1).expand(-1, seq_len, -1)  # [batch, seq_len, d_model]\n",
    "        x = x + t_emb\n",
    "\n",
    "        # Add positional encoding\n",
    "        x = self.pos_encoding(x)\n",
    "\n",
    "        # Transformer layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Output projection\n",
    "        x = self.output_proj(x)  # [batch, seq_len, 3]\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create model instance\n",
    "model = SketchDiffusionModel(d_model=256, nhead=8, num_layers=6)\n",
    "\n",
    "# Test forward pass\n",
    "batch_size = 4\n",
    "seq_len = 200\n",
    "x = torch.randn(batch_size, seq_len, 3)\n",
    "t = torch.randint(0, 1000, (batch_size,))\n",
    "\n",
    "output = model(x, t)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class NoiseSchedule:\n",
    "    def __init__(self, num_timesteps=1000, beta_start=0.0001, beta_end=0.02):\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        # Linear schedule\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "\n",
    "        # Calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n",
    "\n",
    "        # Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        self.posterior_variance = self.betas * (1. - self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)\n",
    "\n",
    "noise_schedule = NoiseSchedule()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def forward_diffusion(x0, t, noise_schedule):\n",
    "    \"\"\"Add noise to data according to diffusion schedule\"\"\"\n",
    "    device = x0.device\n",
    "\n",
    "    # Get noise schedule values\n",
    "    sqrt_alphas_cumprod_t = noise_schedule.sqrt_alphas_cumprod[t].to(device)\n",
    "    sqrt_one_minus_alphas_cumprod_t = noise_schedule.sqrt_one_minus_alphas_cumprod[t].to(device)\n",
    "\n",
    "    # Reshape for broadcasting\n",
    "    sqrt_alphas_cumprod_t = sqrt_alphas_cumprod_t.reshape(-1, 1, 1)\n",
    "    sqrt_one_minus_alphas_cumprod_t = sqrt_one_minus_alphas_cumprod_t.reshape(-1, 1, 1)\n",
    "\n",
    "    # Sample noise\n",
    "    noise = torch.randn_like(x0)\n",
    "\n",
    "    # Add noise\n",
    "    x_t = sqrt_alphas_cumprod_t * x0 + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "\n",
    "    return x_t, noise"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test forward diffusion with cat data\n",
    "sample_batch = torch.stack(cat_sequences[:8])  # Get 8 samples\n",
    "timesteps = torch.randint(0, 1000, (8,))\n",
    "\n",
    "# Add noise\n",
    "noisy_batch, noise = forward_diffusion(sample_batch, timesteps, noise_schedule)\n",
    "\n",
    "print(f\"Original batch shape: {sample_batch.shape}\")\n",
    "print(f\"Noisy batch shape: {noisy_batch.shape}\")\n",
    "print(f\"Noise shape: {noise.shape}\")\n",
    "print(f\"Timesteps: {timesteps}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def diffusion_loss(model, x0, noise_schedule, device):\n",
    "    \"\"\"Calculate diffusion loss\"\"\"\n",
    "    batch_size = x0.shape[0]\n",
    "\n",
    "    # Sample timesteps\n",
    "    t = torch.randint(0, noise_schedule.num_timesteps, (batch_size,), device=device)\n",
    "\n",
    "    # Add noise\n",
    "    x_t, noise = forward_diffusion(x0, t, noise_schedule)\n",
    "\n",
    "    # Predict noise\n",
    "    predicted_noise = model(x_t, t)\n",
    "\n",
    "    # Calculate loss (MSE between actual and predicted noise)\n",
    "    loss = F.mse_loss(predicted_noise, noise)\n",
    "\n",
    "    return loss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Move data to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "sample_batch = sample_batch.to(device)\n",
    "\n",
    "# Calculate loss\n",
    "loss = diffusion_loss(model, sample_batch, noise_schedule, device)\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Section 4: Training Pipeline"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Training hyperparameters\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 50\n",
    "batch_size = 16\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_epoch(model, dataloader, optimizer, noise_schedule, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = diffusion_loss(model, batch, noise_schedule, device)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create cat dataloader\n",
    "cat_tensor = torch.stack(cat_sequences)\n",
    "cat_dataset = SimpleDataset(cat_tensor)\n",
    "cat_loader = DataLoader(cat_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Cat dataset size: {len(cat_dataset)}\")\n",
    "print(f\"Number of batches: {len(cat_loader)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create and setup model for cats\n",
    "cat_model = SketchDiffusionModel(d_model=256, nhead=8, num_layers=6).to(device)\n",
    "cat_optimizer = optim.Adam(cat_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Move noise schedule to device\n",
    "noise_schedule.betas = noise_schedule.betas.to(device)\n",
    "noise_schedule.alphas = noise_schedule.alphas.to(device)\n",
    "noise_schedule.alphas_cumprod = noise_schedule.alphas_cumprod.to(device)\n",
    "noise_schedule.alphas_cumprod_prev = noise_schedule.alphas_cumprod_prev.to(device)\n",
    "noise_schedule.sqrt_alphas_cumprod = noise_schedule.sqrt_alphas_cumprod.to(device)\n",
    "noise_schedule.sqrt_one_minus_alphas_cumprod = noise_schedule.sqrt_one_minus_alphas_cumprod.to(device)\n",
    "noise_schedule.posterior_variance = noise_schedule.posterior_variance.to(device)\n",
    "\n",
    "print(f\"Cat model parameters: {sum(p.numel() for p in cat_model.parameters()):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop for cats\n",
    "cat_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = train_epoch(cat_model, cat_loader, cat_optimizer, noise_schedule, device)\n",
    "    cat_losses.append(avg_loss)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Plot training curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(cat_losses)\n",
    "plt.title('Cat Model Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create models directory\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "# Save cat model\n",
    "torch.save({\n",
    "    'model_state_dict': cat_model.state_dict(),\n",
    "    'optimizer_state_dict': cat_optimizer.state_dict(),\n",
    "    'loss_history': cat_losses,\n",
    "    'epoch': num_epochs\n",
    "}, './models/cat_model.pth')\n",
    "\n",
    "print(\"Cat model saved successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare bus data\n",
    "bus_tensor = torch.stack(all_data['bus'])\n",
    "bus_dataset = SimpleDataset(bus_tensor)\n",
    "bus_loader = DataLoader(bus_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize bus model\n",
    "bus_model = SketchDiffusionModel(d_model=256, nhead=8, num_layers=6).to(device)\n",
    "bus_optimizer = optim.Adam(bus_model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"Bus dataset size: {len(bus_dataset)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training loop for bus\n",
    "bus_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = train_epoch(bus_model, bus_loader, bus_optimizer, noise_schedule, device)\n",
    "    bus_losses.append(avg_loss)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Plot training curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(bus_losses)\n",
    "plt.title('Bus Model Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save bus model\n",
    "torch.save({\n",
    "    'model_state_dict': bus_model.state_dict(),\n",
    "    'optimizer_state_dict': bus_optimizer.state_dict(),\n",
    "    'loss_history': bus_losses,\n",
    "    'epoch': num_epochs\n",
    "}, './models/bus_model.pth')\n",
    "\n",
    "print(\"Bus model saved successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare rabbit data\n",
    "rabbit_tensor = torch.stack(all_data['rabbit'])\n",
    "rabbit_dataset = SimpleDataset(rabbit_tensor)\n",
    "rabbit_loader = DataLoader(rabbit_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize rabbit model\n",
    "rabbit_model = SketchDiffusionModel(d_model=256, nhead=8, num_layers=6).to(device)\n",
    "rabbit_optimizer = optim.Adam(rabbit_model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"Rabbit dataset size: {len(rabbit_dataset)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training loop for rabbit\n",
    "rabbit_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = train_epoch(rabbit_model, rabbit_loader, rabbit_optimizer, noise_schedule, device)\n",
    "    rabbit_losses.append(avg_loss)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Plot training curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rabbit_losses)\n",
    "plt.title('Rabbit Model Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save rabbit model\n",
    "torch.save({\n",
    "    'model_state_dict': rabbit_model.state_dict(),\n",
    "    'optimizer_state_dict': rabbit_optimizer.state_dict(),\n",
    "    'loss_history': rabbit_losses,\n",
    "    'epoch': num_epochs\n",
    "}, './models/rabbit_model.pth')\n",
    "\n",
    "print(\"Rabbit model saved successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot all training curves together\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(cat_losses, label='Cat', color='orange')\n",
    "plt.plot(bus_losses, label='Bus', color='blue')\n",
    "plt.plot(rabbit_losses, label='Rabbit', color='green')\n",
    "plt.title('Training Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(cat_losses[-20:], label='Cat', color='orange')\n",
    "plt.plot(bus_losses[-20:], label='Bus', color='blue')\n",
    "plt.plot(rabbit_losses[-20:], label='Rabbit', color='green')\n",
    "plt.title('Last 20 Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print final training statistics\n",
    "final_losses = {\n",
    "    'cat': cat_losses[-1],\n",
    "    'bus': bus_losses[-1],\n",
    "    'rabbit': rabbit_losses[-1]\n",
    "}\n",
    "\n",
    "print(\"Final Training Losses:\")\n",
    "for category, loss in final_losses.items():\n",
    "    print(f\"  {category.capitalize()}: {loss:.4f}\")\n",
    "\n",
    "print(f\"\\nTotal training time: {num_epochs} epochs per model\")\n",
    "print(\"All models saved to ./models/ directory\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Section 5: Inference Pipeline"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load all three models\n",
    "models = {}\n",
    "for category in ['cat', 'bus', 'rabbit']:\n",
    "    model = SketchDiffusionModel(d_model=256, nhead=8, num_layers=6).to(device)\n",
    "    checkpoint = torch.load(f'./models/{category}_model.pth', map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    models[category] = model\n",
    "\n",
    "len(models)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@torch.no_grad()\n",
    "def denoise_step(model, x_t, t, noise_schedule):\n",
    "    \"\"\"Single denoising step\"\"\"\n",
    "    predicted_noise = model(x_t, t)\n",
    "\n",
    "    alpha_t = noise_schedule.alphas[t].reshape(-1, 1, 1)\n",
    "    alpha_cumprod_t = noise_schedule.alphas_cumprod[t].reshape(-1, 1, 1)\n",
    "    beta_t = noise_schedule.betas[t].reshape(-1, 1, 1)\n",
    "\n",
    "    if t[0] > 0:\n",
    "        alpha_cumprod_prev = noise_schedule.alphas_cumprod[t-1].reshape(-1, 1, 1)\n",
    "        posterior_mean = (\n",
    "                (torch.sqrt(alpha_cumprod_prev) * beta_t) / (1 - alpha_cumprod_t) *\n",
    "                (x_t - torch.sqrt(1 - alpha_cumprod_t) * predicted_noise) / torch.sqrt(alpha_t) +\n",
    "                (torch.sqrt(alpha_t) * (1 - alpha_cumprod_prev)) / (1 - alpha_cumprod_t) * x_t\n",
    "        )\n",
    "\n",
    "        if t[0] > 1:\n",
    "            posterior_variance = noise_schedule.posterior_variance[t].reshape(-1, 1, 1)\n",
    "            noise = torch.randn_like(x_t)\n",
    "            x_prev = posterior_mean + torch.sqrt(posterior_variance) * noise\n",
    "        else:\n",
    "            x_prev = posterior_mean\n",
    "    else:\n",
    "        x_prev = (x_t - torch.sqrt(1 - alpha_cumprod_t) * predicted_noise) / torch.sqrt(alpha_cumprod_t)\n",
    "\n",
    "    return x_prev"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@torch.no_grad()\n",
    "def generate_sample(model, noise_schedule):\n",
    "    \"\"\"Generate one sketch from noise\"\"\"\n",
    "    x = torch.randn(1, 200, 3, device=device)\n",
    "\n",
    "    for t in reversed(range(noise_schedule.num_timesteps)):\n",
    "        t_tensor = torch.tensor([t], device=device)\n",
    "        x = denoise_step(model, x, t_tensor, noise_schedule)\n",
    "\n",
    "    return x.squeeze(0).cpu()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_sketch(sequence, title=\"Generated Sketch\"):\n",
    "    \"\"\"Plot sequence as sketch\"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    current_stroke = []\n",
    "    pen_down = False\n",
    "\n",
    "    for command, x, y in sequence:\n",
    "        if command >= 1.5:  # pen_down\n",
    "            pen_down = True\n",
    "            current_stroke = []\n",
    "        elif -0.5 <= command <= 0.5 and pen_down:  # draw\n",
    "            current_stroke.append([x.item(), y.item()])\n",
    "        elif 0.5 <= command <= 1.5:  # pen_up\n",
    "            if len(current_stroke) > 1:\n",
    "                xs, ys = zip(*current_stroke)\n",
    "                plt.plot(xs, ys, 'b-', linewidth=2)\n",
    "            pen_down = False\n",
    "        elif command >= 2.5:  # end\n",
    "            break\n",
    "\n",
    "    plt.xlim(-1.2, 1.2)\n",
    "    plt.ylim(-1.2, 1.2)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cat_sample = generate_sample(models['cat'], noise_schedule)\n",
    "plot_sketch(cat_sample, \"Generated Cat\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bus_sample = generate_sample(models['bus'], noise_schedule)\n",
    "plot_sketch(bus_sample, \"Generated Bus\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rabbit_sample = generate_sample(models['rabbit'], noise_schedule)\n",
    "plot_sketch(rabbit_sample, \"Generated Rabbit\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "for i, category in enumerate(['cat', 'bus', 'rabbit']):\n",
    "    for j in range(3):\n",
    "        sample = generate_sample(models[category], noise_schedule)\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        current_stroke = []\n",
    "        pen_down = False\n",
    "\n",
    "        for command, x, y in sample:\n",
    "            if command >= 1.5:\n",
    "                pen_down = True\n",
    "                current_stroke = []\n",
    "            elif -0.5 <= command <= 0.5 and pen_down:\n",
    "                current_stroke.append([x.item(), y.item()])\n",
    "            elif 0.5 <= command <= 1.5:\n",
    "                if len(current_stroke) > 1:\n",
    "                    xs, ys = zip(*current_stroke)\n",
    "                    ax.plot(xs, ys, 'b-', linewidth=2)\n",
    "                pen_down = False\n",
    "            elif command >= 2.5:\n",
    "                break\n",
    "\n",
    "        ax.set_xlim(-1.2, 1.2)\n",
    "        ax.set_ylim(-1.2, 1.2)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_title(f'{category.capitalize()} {j+1}')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_strokes(sequence):\n",
    "    \"\"\"Extract strokes from sequence\"\"\"\n",
    "    strokes = []\n",
    "    current_stroke = []\n",
    "    pen_down = False\n",
    "\n",
    "    for command, x, y in sequence:\n",
    "        if command >= 1.5:  # pen_down\n",
    "            pen_down = True\n",
    "            current_stroke = []\n",
    "        elif -0.5 <= command <= 0.5 and pen_down:  # draw\n",
    "            current_stroke.append([x.item(), y.item()])\n",
    "        elif 0.5 <= command <= 1.5:  # pen_up\n",
    "            if len(current_stroke) > 1:\n",
    "                strokes.append(current_stroke.copy())\n",
    "            pen_down = False\n",
    "        elif command >= 2.5:  # end\n",
    "            break\n",
    "\n",
    "    return strokes"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Create animations directory\n",
    "os.makedirs('./animations', exist_ok=True)\n",
    "\n",
    "# Generate and save cat animation\n",
    "cat_sample = generate_sample(models['cat'], noise_schedule)\n",
    "cat_strokes = get_strokes(cat_sample)\n",
    "\n",
    "frames = []\n",
    "for i in range(len(cat_strokes) + 1):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    # Draw strokes up to current frame\n",
    "    for j in range(i):\n",
    "        if j < len(cat_strokes):\n",
    "            xs, ys = zip(*cat_strokes[j])\n",
    "            ax.plot(xs, ys, 'b-', linewidth=3)\n",
    "\n",
    "    ax.set_xlim(-1.2, 1.2)\n",
    "    ax.set_ylim(-1.2, 1.2)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(f'Cat - Stroke: {i}/{len(cat_strokes)}', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Convert to image\n",
    "    fig.canvas.draw()\n",
    "    frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    frames.append(Image.fromarray(frame))\n",
    "    plt.close()\n",
    "\n",
    "# Save GIF\n",
    "frames[0].save('./animations/cat_generation.gif', save_all=True, append_images=frames[1:], duration=800, loop=0)\n",
    "f\"Cat GIF saved with {len(frames)} frames\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate and save bus animation\n",
    "bus_sample = generate_sample(models['bus'], noise_schedule)\n",
    "bus_strokes = get_strokes(bus_sample)\n",
    "\n",
    "frames = []\n",
    "for i in range(len(bus_strokes) + 1):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    for j in range(i):\n",
    "        if j < len(bus_strokes):\n",
    "            xs, ys = zip(*bus_strokes[j])\n",
    "            ax.plot(xs, ys, 'b-', linewidth=3)\n",
    "\n",
    "    ax.set_xlim(-1.2, 1.2)\n",
    "    ax.set_ylim(-1.2, 1.2)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(f'Bus - Stroke: {i}/{len(bus_strokes)}', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    frames.append(Image.fromarray(frame))\n",
    "    plt.close()\n",
    "\n",
    "frames[0].save('./animations/bus_generation.gif', save_all=True, append_images=frames[1:], duration=800, loop=0)\n",
    "f\"Bus GIF saved with {len(frames)} frames\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate and save rabbit animation\n",
    "rabbit_sample = generate_sample(models['rabbit'], noise_schedule)\n",
    "rabbit_strokes = get_strokes(rabbit_sample)\n",
    "\n",
    "frames = []\n",
    "for i in range(len(rabbit_strokes) + 1):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    for j in range(i):\n",
    "        if j < len(rabbit_strokes):\n",
    "            xs, ys = zip(*rabbit_strokes[j])\n",
    "            ax.plot(xs, ys, 'b-', linewidth=3)\n",
    "\n",
    "    ax.set_xlim(-1.2, 1.2)\n",
    "    ax.set_ylim(-1.2, 1.2)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(f'Rabbit - Stroke: {i}/{len(rabbit_strokes)}', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    frames.append(Image.fromarray(frame))\n",
    "    plt.close()\n",
    "\n",
    "frames[0].save('./animations/rabbit_generation.gif', save_all=True, append_images=frames[1:], duration=800, loop=0)\n",
    "f\"Rabbit GIF saved with {len(frames)} frames\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Section 6: Quantitative Evaluation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install required packages\n",
    "try:\n",
    "    import torchvision\n",
    "    from scipy import linalg\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torchvision\", \"scipy\"])\n",
    "    import torchvision\n",
    "    from scipy import linalg\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load test sketches for all categories\n",
    "test_data = {}\n",
    "\n",
    "for category in ['cat', 'bus', 'rabbit']:\n",
    "    # Load raw sketches\n",
    "    with open(f\"./data/{category}.ndjson\", 'r') as f:\n",
    "        sketches = [json.loads(line) for line in f]\n",
    "\n",
    "    # Load test indices\n",
    "    with open(f\"./subset/{category}/indices.json\", 'r') as f:\n",
    "        indices = json.load(f)\n",
    "\n",
    "    test_sketches = [sketches[i] for i in indices[\"test\"]]\n",
    "\n",
    "    # Process test sequences\n",
    "    sequences = []\n",
    "    for sketch in test_sketches:\n",
    "        drawing = sketch[\"drawing\"]\n",
    "\n",
    "        all_points = []\n",
    "        for stroke in drawing:\n",
    "            all_points.extend(zip(stroke[0], stroke[1]))\n",
    "\n",
    "        if not all_points:\n",
    "            continue\n",
    "\n",
    "        all_x, all_y = zip(*all_points)\n",
    "        min_x, max_x = min(all_x), max(all_x)\n",
    "        min_y, max_y = min(all_y), max(all_y)\n",
    "        width = max_x - min_x if max_x > min_x else 1\n",
    "        height = max_y - min_y if max_y > min_y else 1\n",
    "\n",
    "        sequence = []\n",
    "        for stroke in drawing:\n",
    "            sequence.append([2, 0, 0])\n",
    "            for x, y in zip(stroke[0], stroke[1]):\n",
    "                norm_x = 2 * (x - min_x) / width - 1\n",
    "                norm_y = 2 * (y - min_y) / height - 1\n",
    "                sequence.append([0, norm_x, norm_y])\n",
    "            sequence.append([1, 0, 0])\n",
    "        sequence.append([3, 0, 0])\n",
    "\n",
    "        sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "        if len(sequence) > 200:\n",
    "            sequence = sequence[:200]\n",
    "        else:\n",
    "            padding = torch.tensor([[3, 0, 0]] * (200 - len(sequence)))\n",
    "            sequence = torch.cat([sequence, padding])\n",
    "\n",
    "        sequences.append(sequence)\n",
    "\n",
    "    test_data[category] = sequences\n",
    "\n",
    "{k: len(v) for k, v in test_data.items()}"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate same number of samples as test data for each category\n",
    "generated_data = {}\n",
    "\n",
    "for category in ['cat', 'bus', 'rabbit']:\n",
    "    num_samples = len(test_data[category])\n",
    "    samples = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample = generate_sample(models[category], noise_schedule)\n",
    "        samples.append(sample)\n",
    "\n",
    "    generated_data[category] = samples\n",
    "\n",
    "{k: len(v) for k, v in generated_data.items()}"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def sequence_to_image(sequence, size=64):\n",
    "    \"\"\"Convert sequence to rasterized image\"\"\"\n",
    "    # Create blank image\n",
    "    img = np.ones((size, size, 3), dtype=np.uint8) * 255  # White background\n",
    "\n",
    "    current_stroke = []\n",
    "    pen_down = False\n",
    "\n",
    "    for command, x, y in sequence:\n",
    "        if command >= 1.5:  # pen_down\n",
    "            pen_down = True\n",
    "            current_stroke = []\n",
    "        elif -0.5 <= command <= 0.5 and pen_down:  # draw\n",
    "            # Convert normalized coords to image coords\n",
    "            img_x = int((x + 1.2) / 2.4 * size)\n",
    "            img_y = int((y + 1.2) / 2.4 * size)\n",
    "            img_x = max(0, min(size-1, img_x))\n",
    "            img_y = max(0, min(size-1, img_y))\n",
    "            current_stroke.append([img_x, img_y])\n",
    "        elif 0.5 <= command <= 1.5:  # pen_up\n",
    "            # Draw the stroke\n",
    "            if len(current_stroke) > 1:\n",
    "                for i in range(len(current_stroke)-1):\n",
    "                    x1, y1 = current_stroke[i]\n",
    "                    x2, y2 = current_stroke[i+1]\n",
    "                    # Simple line drawing\n",
    "                    dx = abs(x2 - x1)\n",
    "                    dy = abs(y2 - y1)\n",
    "                    n_points = max(dx, dy, 1)\n",
    "                    for j in range(n_points + 1):\n",
    "                        t = j / n_points if n_points > 0 else 0\n",
    "                        px = int(x1 + t * (x2 - x1))\n",
    "                        py = int(y1 + t * (y2 - y1))\n",
    "                        if 0 <= px < size and 0 <= py < size:\n",
    "                            img[py, px] = [0, 0, 0]  # Black line\n",
    "            pen_down = False\n",
    "        elif command >= 2.5:  # end\n",
    "            break\n",
    "\n",
    "    return img"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load pre-trained InceptionV3 for feature extraction\n",
    "inception = models.inception_v3(pretrained=True, transform_input=False)\n",
    "inception.fc = torch.nn.Identity()  # Remove final classification layer\n",
    "inception.eval()\n",
    "inception = inception.to(device)\n",
    "\n",
    "# Image preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@torch.no_grad()\n",
    "def extract_features(images, model, batch_size=32):\n",
    "    \"\"\"Extract InceptionV3 features from images\"\"\"\n",
    "    features = []\n",
    "\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch_imgs = images[i:i+batch_size]\n",
    "\n",
    "        # Preprocess batch\n",
    "        batch_tensors = []\n",
    "        for img in batch_imgs:\n",
    "            tensor = preprocess(img)\n",
    "            batch_tensors.append(tensor)\n",
    "\n",
    "        batch_tensor = torch.stack(batch_tensors).to(device)\n",
    "\n",
    "        # Extract features\n",
    "        batch_features = model(batch_tensor)\n",
    "        features.append(batch_features.cpu())\n",
    "\n",
    "    return torch.cat(features, dim=0)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_fid(real_features, fake_features):\n",
    "    \"\"\"Calculate Fr√©chet Inception Distance\"\"\"\n",
    "    # Convert to numpy\n",
    "    real_features = real_features.numpy()\n",
    "    fake_features = fake_features.numpy()\n",
    "\n",
    "    # Calculate means and covariances\n",
    "    mu1, sigma1 = real_features.mean(axis=0), np.cov(real_features, rowvar=False)\n",
    "    mu2, sigma2 = fake_features.mean(axis=0), np.cov(fake_features, rowvar=False)\n",
    "\n",
    "    # Calculate FID\n",
    "    diff = mu1 - mu2\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "\n",
    "    if not np.isfinite(covmean).all():\n",
    "        covmean = linalg.sqrtm((sigma1 + sigma2) / 2)\n",
    "\n",
    "    fid = diff.dot(diff) + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
    "    return float(fid)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_kid(real_features, fake_features):\n",
    "    \"\"\"Calculate Kernel Inception Distance\"\"\"\n",
    "    real_features = real_features.numpy()\n",
    "    fake_features = fake_features.numpy()\n",
    "\n",
    "    n = real_features.shape[0]\n",
    "    m = fake_features.shape[0]\n",
    "\n",
    "    # Polynomial kernel\n",
    "    def polynomial_kernel(X, Y, degree=3, gamma=None, coef0=1):\n",
    "        if gamma is None:\n",
    "            gamma = 1.0 / X.shape[1]\n",
    "        K = (gamma * np.dot(X, Y.T) + coef0) ** degree\n",
    "        return K\n",
    "\n",
    "    # Calculate kernel matrices\n",
    "    Kxx = polynomial_kernel(real_features, real_features)\n",
    "    Kxy = polynomial_kernel(real_features, fake_features)\n",
    "    Kyy = polynomial_kernel(fake_features, fake_features)\n",
    "\n",
    "    # Calculate KID\n",
    "    kid = (Kxx.sum() / (n * n) + Kyy.sum() / (m * m) - 2 * Kxy.sum() / (n * m))\n",
    "    return float(kid)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Calculate metrics for all categories\n",
    "results = {}\n",
    "\n",
    "for category in ['cat', 'bus', 'rabbit']:\n",
    "    print(f\"Processing {category}...\")\n",
    "\n",
    "    # Extract features\n",
    "    real_features = extract_features(real_images[category], inception)\n",
    "    fake_features = extract_features(generated_images[category], inception)\n",
    "\n",
    "    # Calculate metrics\n",
    "    fid_score = calculate_fid(real_features, fake_features)\n",
    "    kid_score = calculate_kid(real_features, fake_features)\n",
    "\n",
    "    results[category] = {\n",
    "        'FID': fid_score,\n",
    "        'KID': kid_score\n",
    "    }\n",
    "\n",
    "results"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create results table\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results).T\n",
    "df = df.round(4)\n",
    "\n",
    "print(\"Quantitative Evaluation Results:\")\n",
    "print(\"=\" * 40)\n",
    "print(df.to_string())\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Individual scores as required\n",
    "print(\"\\nIndividual Scores:\")\n",
    "for category in ['cat', 'bus', 'rabbit']:\n",
    "    print(f\"{category.capitalize()}: FID = {results[category]['FID']:.4f}, KID = {results[category]['KID']:.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Section 7: Qualitative Evaluation and Discussion"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate fresh samples for comparison\n",
    "comparison_samples = {}\n",
    "for category in ['cat', 'bus', 'rabbit']:\n",
    "    samples = []\n",
    "    for i in range(6):\n",
    "        sample = generate_sample(models[category], noise_schedule)\n",
    "        samples.append(sample)\n",
    "    comparison_samples[category] = samples"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(6, 6, figsize=(18, 18))\n",
    "\n",
    "for cat_idx, category in enumerate(['cat', 'bus', 'rabbit']):\n",
    "    for i in range(6):\n",
    "        # Real sketch\n",
    "        real_seq = test_data[category][i]\n",
    "        ax_real = axes[cat_idx*2, i]\n",
    "\n",
    "        current_stroke = []\n",
    "        pen_down = False\n",
    "\n",
    "        for command, x, y in real_seq:\n",
    "            if command >= 1.5:\n",
    "                pen_down = True\n",
    "                current_stroke = []\n",
    "            elif -0.5 <= command <= 0.5 and pen_down:\n",
    "                current_stroke.append([x.item(), y.item()])\n",
    "            elif 0.5 <= command <= 1.5:\n",
    "                if len(current_stroke) > 1:\n",
    "                    xs, ys = zip(*current_stroke)\n",
    "                    ax_real.plot(xs, ys, 'b-', linewidth=2)\n",
    "                pen_down = False\n",
    "            elif command >= 2.5:\n",
    "                break\n",
    "\n",
    "        ax_real.set_xlim(-1.2, 1.2)\n",
    "        ax_real.set_ylim(-1.2, 1.2)\n",
    "        ax_real.set_aspect('equal')\n",
    "        ax_real.invert_yaxis()\n",
    "        ax_real.set_title(f'Real {category.capitalize()} {i+1}', fontsize=10)\n",
    "        ax_real.grid(True, alpha=0.3)\n",
    "\n",
    "        # Generated sketch\n",
    "        gen_seq = comparison_samples[category][i]\n",
    "        ax_gen = axes[cat_idx*2+1, i]\n",
    "\n",
    "        current_stroke = []\n",
    "        pen_down = False\n",
    "\n",
    "        for command, x, y in gen_seq:\n",
    "            if command >= 1.5:\n",
    "                pen_down = True\n",
    "                current_stroke = []\n",
    "            elif -0.5 <= command <= 0.5 and pen_down:\n",
    "                current_stroke.append([x.item(), y.item()])\n",
    "            elif 0.5 <= command <= 1.5:\n",
    "                if len(current_stroke) > 1:\n",
    "                    xs, ys = zip(*current_stroke)\n",
    "                    ax_gen.plot(xs, ys, 'r-', linewidth=2)\n",
    "                pen_down = False\n",
    "            elif command >= 2.5:\n",
    "                break\n",
    "\n",
    "        ax_gen.set_xlim(-1.2, 1.2)\n",
    "        ax_gen.set_ylim(-1.2, 1.2)\n",
    "        ax_gen.set_aspect('equal')\n",
    "        ax_gen.invert_yaxis()\n",
    "        ax_gen.set_title(f'Generated {category.capitalize()} {i+1}', fontsize=10)\n",
    "        ax_gen.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Analyze stroke counts in real vs generated\n",
    "stroke_analysis = {}\n",
    "\n",
    "for category in ['cat', 'bus', 'rabbit']:\n",
    "    real_strokes = []\n",
    "    gen_strokes = []\n",
    "\n",
    "    # Count strokes in real data (sample 100)\n",
    "    for seq in test_data[category][:100]:\n",
    "        stroke_count = (seq[:, 0] == 2).sum().item()\n",
    "        real_strokes.append(stroke_count)\n",
    "\n",
    "    # Count strokes in generated data\n",
    "    for seq in comparison_samples[category]:\n",
    "        stroke_count = (seq[:, 0] >= 1.5).sum().item()\n",
    "        gen_strokes.append(stroke_count)\n",
    "\n",
    "    stroke_analysis[category] = {\n",
    "        'real_mean': np.mean(real_strokes),\n",
    "        'real_std': np.std(real_strokes),\n",
    "        'gen_mean': np.mean(gen_strokes),\n",
    "        'gen_std': np.std(gen_strokes)\n",
    "    }\n",
    "\n",
    "stroke_analysis"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, category in enumerate(['cat', 'bus', 'rabbit']):\n",
    "    data = stroke_analysis[category]\n",
    "\n",
    "    categories_plot = ['Real', 'Generated']\n",
    "    means = [data['real_mean'], data['gen_mean']]\n",
    "    stds = [data['real_std'], data['gen_std']]\n",
    "\n",
    "    axes[i].bar(categories_plot, means, yerr=stds, capsize=5,\n",
    "                color=['blue', 'red'], alpha=0.7)\n",
    "    axes[i].set_title(f'{category.capitalize()} - Stroke Count')\n",
    "    axes[i].set_ylabel('Average Number of Strokes')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Combine all performance metrics\n",
    "performance_summary = {}\n",
    "\n",
    "for category in ['cat', 'bus', 'rabbit']:\n",
    "    fid = results[category]['FID']\n",
    "    kid = results[category]['KID']\n",
    "    dataset_size = len(all_data[category])\n",
    "\n",
    "    # Get final training loss\n",
    "    checkpoint = torch.load(f'./models/{category}_model.pth', map_location='cpu')\n",
    "    final_loss = checkpoint['loss_history'][-1] if 'loss_history' in checkpoint else None\n",
    "\n",
    "    performance_summary[category] = {\n",
    "        'Dataset Size': dataset_size,\n",
    "        'Final Loss': final_loss,\n",
    "        'FID Score': fid,\n",
    "        'KID Score': kid\n",
    "    }\n",
    "\n",
    "pd.DataFrame(performance_summary).T.round(4)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, category in enumerate(['cat', 'bus', 'rabbit']):\n",
    "    checkpoint = torch.load(f'./models/{category}_model.pth', map_location='cpu')\n",
    "    if 'loss_history' in checkpoint:\n",
    "        loss_history = checkpoint['loss_history']\n",
    "        axes[i].plot(loss_history)\n",
    "        axes[i].set_title(f'{category.capitalize()} Training Loss')\n",
    "        axes[i].set_xlabel('Epoch')\n",
    "        axes[i].set_ylabel('Loss')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate larger sample set for diversity assessment\n",
    "fig, axes = plt.subplots(3, 8, figsize=(20, 8))\n",
    "\n",
    "for cat_idx, category in enumerate(['cat', 'bus', 'rabbit']):\n",
    "    for i in range(8):\n",
    "        sample = generate_sample(models[category], noise_schedule)\n",
    "        ax = axes[cat_idx, i]\n",
    "\n",
    "        current_stroke = []\n",
    "        pen_down = False\n",
    "\n",
    "        for command, x, y in sample:\n",
    "            if command >= 1.5:\n",
    "                pen_down = True\n",
    "                current_stroke = []\n",
    "            elif -0.5 <= command <= 0.5 and pen_down:\n",
    "                current_stroke.append([x.item(), y.item()])\n",
    "            elif 0.5 <= command <= 1.5:\n",
    "                if len(current_stroke) > 1:\n",
    "                    xs, ys = zip(*current_stroke)\n",
    "                    ax.plot(xs, ys, 'b-', linewidth=1.5)\n",
    "                pen_down = False\n",
    "            elif command >= 2.5:\n",
    "                break\n",
    "\n",
    "        ax.set_xlim(-1.2, 1.2)\n",
    "        ax.set_ylim(-1.2, 1.2)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.invert_yaxis()\n",
    "        ax.axis('off')\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f'{category.capitalize()}', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Generated Sample Diversity', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Display final FID and KID scores as required by assignment\n",
    "final_results = pd.DataFrame(results).T\n",
    "final_results.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VEme3no2Xpc"
   },
   "source": [
    "# References\n",
    "\n",
    "‚ùó Do not forget to include the references you used when filling out the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERleXF7C2Zl9"
   },
   "source": [
    "- [What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)\n",
    "- [Teaching Machines to Draw](https://research.google/blog/teaching-machines-to-draw/)\n",
    "- []()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
